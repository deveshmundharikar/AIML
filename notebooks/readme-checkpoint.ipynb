{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10426673-d1ae-486f-81c9-753e162aa8b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import GridSearchCV\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "# ----------------- Step 1: Set up the Hyperparameter Grid -----------------\n",
    "\n",
    "# Define the model we want to tune\n",
    "lr_model_for_tuning = LogisticRegression(random_state=42)\n",
    "\n",
    "# Define the grid of parameters to search. We will focus on 'C'.\n",
    "# These values are common starting points: from weak to strong regularization.\n",
    "param_grid = {\n",
    "    'C': [0.1, 0.5, 1, 5, 10],  # Inverse of regularization strength\n",
    "    'solver': ['liblinear']     # A good solver for this kind of problem\n",
    "}\n",
    "\n",
    "\n",
    "# ----------------- Step 2: Set up and Run GridSearchCV -----------------\n",
    "\n",
    "# Initialize GridSearchCV\n",
    "# cv=5 means 5-fold cross-validation.\n",
    "# n_jobs=-1 uses all available CPU cores to speed up the process.\n",
    "# verbose=2 will print progress updates.\n",
    "grid_search = GridSearchCV(estimator=lr_model_for_tuning, \n",
    "                           param_grid=param_grid, \n",
    "                           cv=5, \n",
    "                           n_jobs=-1, \n",
    "                           verbose=2)\n",
    "\n",
    "# Fit the grid search to the data\n",
    "# This will train and test the model for each 'C' value using cross-validation.\n",
    "# It can take a few minutes!\n",
    "print(\"Starting GridSearchCV for Logistic Regression...\")\n",
    "grid_search.fit(X_train_tfidf, y_train)\n",
    "print(\"GridSearchCV complete.\")\n",
    "\n",
    "\n",
    "# ----------------- Step 3: Analyze the Results -----------------\n",
    "\n",
    "# Print the best parameters found\n",
    "print(f\"\\nBest Parameters found: {grid_search.best_params_}\")\n",
    "\n",
    "# Print the best cross-validation score\n",
    "print(f\"Best cross-validation accuracy: {grid_search.best_score_:.4f}\")\n",
    "\n",
    "# The grid_search object is now a trained model with the best parameters.\n",
    "# Let's get its performance on the actual test set.\n",
    "best_lr_model = grid_search.best_estimator_\n",
    "y_pred_tuned = best_lr_model.predict(X_test_tfidf)\n",
    "\n",
    "# Calculate and print the final accuracy on the test set\n",
    "accuracy_tuned = accuracy_score(y_test, y_pred_tuned)\n",
    "print(f\"\\nTest Accuracy of Tuned Logistic Regression Model: {accuracy_tuned:.4f}\")\n",
    "\n",
    "\n",
    "# ----------------- Step 4: Compare with Baseline Model -----------------\n",
    "print(\"\\n--- Model Comparison ---\")\n",
    "print(f\"Logistic Regression (Baseline) Accuracy: {accuracy:.4f}\")\n",
    "print(f\"Tuned Logistic Regression Accuracy:      {accuracy_tuned:.4f}\")\n",
    "print(\"------------------------\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae78b9ce-2f90-491a-aad9-79130c60e8db",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.ensemble import RandomForestClassifier, AdaBoostClassifier\n",
    "from sklearn.linear_model import PassiveAggressiveClassifier\n",
    "from lightgbm import LGBMClassifier\n",
    "from sklearn.metrics import accuracy_score\n",
    "import time\n",
    "\n",
    "# X_train_tfidf, y_train, X_test_tfidf, y_test are already loaded\n",
    "# from our previous steps.\n",
    "\n",
    "# --- Step 6: Model Showdown ---\n",
    "\n",
    "# 1. Define the models we want to test\n",
    "models_to_test = {\n",
    "    \n",
    "    \"Linear SVC\": LinearSVC(random_state=42),\n",
    "    \"Random Forest\": RandomForestClassifier(random_state=42, n_jobs=-1),\n",
    "    \"LightGBM\": LGBMClassifier(random_state=42),\n",
    "    \"Passive Aggressive\": PassiveAggressiveClassifier(random_state=42),\n",
    "    \"AdaBoost\": AdaBoostClassifier(random_state=42)\n",
    "}\n",
    "\n",
    "# 2. Loop through each model to train, predict, and evaluate\n",
    "model_performance = []\n",
    "\n",
    "print(\"--- Starting Model Showdown ---\")\n",
    "\n",
    "for name, model in models_to_test.items():\n",
    "    print(f\"Training and evaluating {name}...\")\n",
    "    start_time = time.time()\n",
    "    \n",
    "    # Train the model (Logistic Regression is already trained)\n",
    "    if name != \"Logistic Regression\":\n",
    "        model.fit(X_train_tfidf, y_train)\n",
    "    \n",
    "    # Predict on the test data\n",
    "    y_pred = model.predict(X_test_tfidf)\n",
    "    \n",
    "    # Calculate accuracy\n",
    "    accuracy = accuracy_score(y_test, y_pred)\n",
    "    \n",
    "    end_time = time.time()\n",
    "    training_time = end_time - start_time\n",
    "    \n",
    "    # Store the results\n",
    "    model_performance.append({\n",
    "        \"Model\": name,\n",
    "        \"Accuracy\": accuracy,\n",
    "        \"Time (s)\": training_time\n",
    "    })\n",
    "    \n",
    "    print(f\"  -> {name} Accuracy: {accuracy:.4f}\")\n",
    "    print(f\"  -> Time taken: {training_time:.2f} seconds\\n\")\n",
    "\n",
    "print(\"--- Model Showdown Complete ---\")\n",
    "\n",
    "# 3. Display the results in a sorted DataFrame\n",
    "performance_df = pd.DataFrame(model_performance)\n",
    "performance_df = performance_df.sort_values(by=\"Accuracy\", ascending=False)\n",
    "performance_df = performance_df.set_index(\"Model\")\n",
    "\n",
    "print(\"\\n--- Final Model Performance Comparison ---\")\n",
    "print(performance_df)\n",
    "\n",
    "# Find the best model from the test\n",
    "best_model_name = performance_df.index[0]\n",
    "best_model_accuracy = performance_df.iloc[0]['Accuracy']\n",
    "\n",
    "print(f\"\\nüèÜ New Champion Found: {best_model_name} with an accuracy of {best_model_accuracy:.4f}!\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
